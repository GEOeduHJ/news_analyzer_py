import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from wordcloud import WordCloud
from collections import Counter
from collections import Counter, defaultdict
import networkx as nx
import re
import folium
from folium.plugins import HeatMap
from streamlit_folium import folium_static
import matplotlib.pyplot as plt
import os
import json
import platform
from PIL import Image
import io
import base64

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì œëª©
st.title("ğŸ“° ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (xlsx)", type=["xlsx"])

# ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
def process_data(uploaded_file):
    try:
        # ì—‘ì…€ íŒŒì¼ ë¡œë“œ
        news_df = pd.read_excel(uploaded_file, engine='openpyxl')
        
        # ì»¬ëŸ¼ ì´ë¦„ ë§¤í•‘
        column_mapping = {
            "ì¼ì": "ì‘ì„±/ê²Œì‹œì¼ì",
            "ì œëª©": "ê¸°ì‚¬ì œëª©",
            "ê¸°ê´€": "ê´€ë ¨ê¸°ê´€",
            "íŠ¹ì„±ì¶”ì¶œ(ê°€ì¤‘ì¹˜ìˆœ ìƒìœ„ 50ê°œ)": "í‚¤ì›Œë“œ",
            "URL": "ê¸°ì‚¬ë§í¬"
        }
        
        # ê¸°ì¡´ ì»¬ëŸ¼ ì¤‘ ë§¤í•‘ëœ ì»¬ëŸ¼ë§Œ ì„ íƒ
        existing_columns = [col for col in column_mapping.keys() if col in news_df.columns]
        news_df = news_df[existing_columns]
        
        # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½
        news_df = news_df.rename(columns=column_mapping)
        
        # ì¤‘ë³µ ì»¬ëŸ¼ ì œê±°
        news_df = news_df.loc[:, ~news_df.columns.duplicated()]
        
        # 'ì¼ì' ì»¬ëŸ¼ì—ì„œ 'ì—°ë„' ì»¬ëŸ¼ ìƒì„±
        if 'ì‘ì„±/ê²Œì‹œì¼ì' in news_df.columns:
            try:
                # yyyymmdd í˜•ì‹ì—ì„œ ì•ì˜ 4ìë¦¬(ì—°ë„) ì¶”ì¶œ
                news_df['ì—°ë„'] = news_df['ì‘ì„±/ê²Œì‹œì¼ì'].astype(str).str[:4]
            except Exception as e:
                st.error(f"'ì¼ì' ì»¬ëŸ¼ì—ì„œ ì—°ë„ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                raise
        else:
            st.error("íŒŒì¼ì— 'ì¼ì' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            raise ValueError("ì¼ì ì»¬ëŸ¼ ì—†ìŒ")
            
        return news_df
    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        raise

if uploaded_file is not None:
    try:
        # ë°ì´í„° ì²˜ë¦¬
        news_df = process_data(uploaded_file)
        
        # ë°ì´í„° í‘œì‹œ
        st.markdown("---")
        st.header("ğŸ“Š ë°ì´í„° íƒìƒ‰")
        
        # ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
        search_text = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥", "", placeholder="ì—¬ê¸°ì— ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    except Exception as e:
        st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.info("ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        raise
        
    if search_text:
            # ëª¨ë“  í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ë°ì´í„° í•„í„°ë§
            filtered_df = news_df[
                news_df.apply(
                    lambda row: any(search_text.lower() in str(cell).lower() 
                                   for cell in row if pd.notna(cell)),
                    axis=1
                )
            ]
            
            if len(filtered_df) == 0:
                st.warning(f"'{search_text}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.write(f"ê²€ìƒ‰ ê²°ê³¼: {len(filtered_df)}ê±´")
                display_df = filtered_df
    else:
        display_df = news_df
        
    # ë°ì´í„° í‘œì‹œ ì„¤ì •
    display_df = display_df.copy()
    
    # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (ì›ë³¸ ë°ì´í„°ëŠ” ìœ ì§€í•˜ê³  ë³´ì—¬ì£¼ê¸°ìš© ì»¬ëŸ¼ ìƒì„±)
    if 'ì‘ì„±/ê²Œì‹œì¼ì' in display_df.columns:
        display_df['í‘œì‹œìš©_ì‘ì„±ì¼ì'] = pd.to_datetime(
            display_df['ì‘ì„±/ê²Œì‹œì¼ì'].astype(str).str.replace('[^0-9]', ''),  # ìˆ«ìë§Œ ë‚¨ê¸°ê¸°
            format='%Y%m%d',
            errors='coerce'  # ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œëŠ” NaTë¡œ ë³€í™˜
        ).dt.strftime('%Y.%m.%d')
        
        # ì—°ë„ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ìƒì„± (ë¶„ì„ìš©)
        if 'ì—°ë„' not in display_df.columns:
            display_df['ì—°ë„'] = display_df['ì‘ì„±/ê²Œì‹œì¼ì'].astype(str).str[:4]
    
    # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ (ì—°ë„ ì»¬ëŸ¼ì€ ë¶„ì„ìš©ìœ¼ë¡œ ìœ ì§€)
    display_columns = ["í‘œì‹œìš©_ì‘ì„±ì¼ì", "ê¸°ì‚¬ì œëª©", "ê´€ë ¨ê¸°ê´€", "í‚¤ì›Œë“œ", "ê¸°ì‚¬ë§í¬"]
    display_columns = [col for col in display_columns if col in display_df.columns]
    
    # í˜ì´ì§€ë„¤ì´ì…˜ ì„¤ì •
    items_per_page = st.select_slider(
        "í˜ì´ì§€ë‹¹ í‘œì‹œí•  ë°ì´í„° ìˆ˜",
        options=[10, 50, 100, 200, 500],
        value=100,
        key="items_per_page"
    )
    
    # ì´ í˜ì´ì§€ ìˆ˜ ê³„ì‚°
    total_pages = max(1, (len(display_df) - 1) // items_per_page + 1)
    
    # í˜ì´ì§€ ì„ íƒ ë²„íŠ¼
    col1, col2, _ = st.columns([1, 2, 3])
    with col1:
        st.write(f"ì´ {len(display_df):,}ê°œ í•­ëª© / {total_pages}í˜ì´ì§€")
    
    # í˜ì´ì§€ë„¤ì´ì…˜ ì»¨íŠ¸ë¡¤
    if total_pages > 1:
        page_cols = st.columns(min(10, total_pages + 2))
        
        # ì´ì „ í˜ì´ì§€ ë²„íŠ¼
        with page_cols[0]:
            prev_page = st.button("â—€", key="prev_page")
            if prev_page and st.session_state.get('current_page', 1) > 1:
                st.session_state['current_page'] -= 1
        
        # í˜ì´ì§€ ë²ˆí˜¸ ë²„íŠ¼
        current_page = st.session_state.get('current_page', 1)
        start_page = max(1, min(current_page - 4, total_pages - 8))
        end_page = min(start_page + 9, total_pages)
        
        for i, col in enumerate(page_cols[1:-1]):
            page_num = start_page + i
            if page_num > end_page:
                break
                
            with col:
                if st.button(str(page_num), key=f"page_{page_num}"):
                    st.session_state['current_page'] = page_num
        
        # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼
        with page_cols[-1]:
            next_page = st.button("â–¶", key="next_page")
            if next_page and st.session_state.get('current_page', 1) < total_pages:
                st.session_state['current_page'] += 1
        
        current_page = st.session_state.get('current_page', 1)
    else:
        current_page = 1
    
    # í˜„ì¬ í˜ì´ì§€ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„° ì¶”ì¶œ
    start_idx = (current_page - 1) * items_per_page
    end_idx = min(current_page * items_per_page, len(display_df))
    
    # ë°ì´í„° í‘œì‹œ (ì»¬ëŸ¼ëª…ì„ ê¹”ë”í•˜ê²Œ í‘œì‹œ)
    display_df_renamed = display_df[display_columns].rename(columns={
        'í‘œì‹œìš©_ì‘ì„±ì¼ì': 'ì‘ì„±/ê²Œì‹œì¼ì'
    })
    
    st.dataframe(
        display_df_renamed.iloc[start_idx:end_idx],
        use_container_width=True,
        hide_index=True,
        column_config={
            "ê¸°ì‚¬ë§í¬": st.column_config.LinkColumn("ê¸°ì‚¬ë§í¬", display_text="ë§í¬ ì´ë™")
        }
    )
    
    # í˜„ì¬ í‘œì‹œ ì¤‘ì¸ ë°ì´í„° ë²”ìœ„ í‘œì‹œ
    st.caption(f"{start_idx + 1:,} - {end_idx:,} / ì´ {len(display_df):,}ê°œ (í˜ì´ì§€ {current_page}/{total_pages})")
        
    
    # ì§€ëª… ë¹ˆë„ìˆ˜ íˆíŠ¸ë§µ
    st.markdown("---")
    st.header("ğŸ—ºï¸ ë¶„ì„ 1: ì§€ëª… ë¹ˆë„ìˆ˜ íˆíŠ¸ë§µ")
    
    if 'í‚¤ì›Œë“œ' in display_df.columns:
        @st.cache_data(ttl=3600)  # 1ì‹œê°„ ë™ì•ˆ ìºì‹œ ìœ ì§€
        def load_sigungu_coordinates():
            """GitHubì—ì„œ ì‹œêµ°êµ¬ ì¢Œí‘œ ë°ì´í„° ë¡œë“œ"""
            import pandas as pd
            
            # GitHub raw URL - ì—¬ê¸°ë¥¼ ì‹¤ì œ GitHub raw URLë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”
            GITHUB_RAW_URL = "https://raw.githubusercontent.com/GEOeduHJ/news_analyzer_py/refs/heads/main/sigungu_coordinates.csv"
            
            try:
                # GitHubì—ì„œ CSV íŒŒì¼ ë¡œë“œ
                df = pd.read_csv(GITHUB_RAW_URL)
                
                # í•„ìš”í•œ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
                required_columns = ['sido', 'sigungu', 'lat', 'lon']
                if not all(col in df.columns for col in required_columns):
                    st.error("CSV íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. 'sido', 'sigungu', 'lat', 'lon' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    return {}
                
                # ì‹œêµ°êµ¬ëª…ì„ í‚¤ë¡œ, ìœ„ë„ì™€ ê²½ë„ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±
                coords_dict = {}
                for _, row in df.iterrows():
                    location = row['sigungu']
                    try:
                        coords_dict[location] = {
                            'lat': float(row['lat']),
                            'lon': float(row['lon'])
                        }
                    except (ValueError, TypeError):
                        continue  # ìœ íš¨í•˜ì§€ ì•Šì€ ì¢Œí‘œëŠ” ê±´ë„ˆëœë‹ˆë‹¤
                
                if not coords_dict:
                    st.error("ìœ íš¨í•œ ì¢Œí‘œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return {}
                    
                return coords_dict
                
            except Exception as e:
                st.error(f"GitHubì—ì„œ ì‹œêµ°êµ¬ ì¢Œí‘œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.info(f"URL í™•ì¸: {GITHUB_RAW_URL}")
                return {}
                
        # ì‹œêµ°êµ¬ ì¢Œí‘œ ë°ì´í„° ë¡œë“œ
        coords_dict = load_sigungu_coordinates()
            
        if coords_dict:
            # í‚¤ì›Œë“œì—ì„œ ì§€ëª… ì¶”ì¶œ ë° ë¹ˆë„ìˆ˜ ê³„ì‚°
            def get_location_frequency(keywords_series, coords_dict):
                """í‚¤ì›Œë“œ ì‹œë¦¬ì¦ˆì—ì„œ ì§€ëª… ë¹ˆë„ìˆ˜ë¥¼ ê³„ì‚°"""
                location_counts = defaultdict(int)

                # ëª¨ë“  ì‹œêµ°êµ¬ëª…ì—ì„œ ì ‘ë¯¸ì‚¬ë¥¼ ì œê±°í•œ ê¸°ë³¸ ì´ë¦„ë§Œ ì €ì¥
                base_names = {loc: loc.replace('ì‹œ', '').replace('êµ°', '').replace('êµ¬', '') 
                            for loc in coords_dict.keys()}
    
                for keywords in keywords_series.dropna():
                    if not isinstance(keywords, str):
                        continue
                    
                    # í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ ë‹¤ì–‘í•œ êµ¬ë¶„ìë¡œ ë¶„ë¦¬
                    for kw in re.split(r'[\s,;:/()]+', keywords.strip()):
                        kw = kw.strip()
                        if not kw or len(kw) < 2:
                            continue
                        
                        # ì ‘ë¯¸ì‚¬ ì œê±°í•œ í‚¤ì›Œë“œë¡œ ë¹„êµ
                        kw_base = kw.replace('ì‹œ', '').replace('êµ°', '').replace('êµ¬', '')
                    
                        # ëª¨ë“  ì‹œêµ°êµ¬ëª…ê³¼ ë¹„êµ
                        for location, base_name in base_names.items():
                            if base_name in kw_base:
                                location_counts[location] += 1
                                break

                return location_counts
                
            # ì§€ëª… ë¹ˆë„ìˆ˜ ê³„ì‚°
            location_counts = get_location_frequency(display_df['í‚¤ì›Œë“œ'], coords_dict)
    
            if location_counts and sum(location_counts.values()) > 0:
                # íˆíŠ¸ë§µ ìƒì„±
                def create_heatmap(location_counts, coords_dict):
                    """ì§€ëª… ë¹ˆë„ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íˆíŠ¸ë§µ ìƒì„±"""
                    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
                    df_locations = pd.DataFrame({
                        'location': list(location_counts.keys()),
                        'count': list(location_counts.values())
                        })
                        
                    # ì¢Œí‘œ ì¶”ê°€
                    df_locations['lat'] = df_locations['location'].apply(
                        lambda x: coords_dict.get(x, {}).get('lat') if x in coords_dict else None
                    )
                    df_locations['lon'] = df_locations['location'].apply(
                        lambda x: coords_dict.get(x, {}).get('lon') if x in coords_dict else None
                    )
                        
                    # ì¢Œí‘œê°€ ì—†ëŠ” í–‰ ì œê±°
                    df_locations = df_locations.dropna(subset=['lat', 'lon'])
                        
                    if df_locations.empty:
                        st.warning("ìœ íš¨í•œ ì¢Œí‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        return None
                        
                    # ì§€ë„ ìƒì„± (í•œêµ­ ì¤‘ì‹¬)
                    m = folium.Map(location=[36.5, 127.5], zoom_start=7, tiles='cartodbpositron')
                        
                    # íˆíŠ¸ë§µ ë°ì´í„° ì¤€ë¹„
                    heat_data = [[row['lat'], row['lon'], row['count']] for _, row in df_locations.iterrows()]
                        
                    # íˆíŠ¸ë§µ ì¶”ê°€
                    HeatMap(heat_data, radius=15, blur=10).add_to(m)
                        
                    # ìƒìœ„ 10ê°œ ì§€ëª…ì— ë§ˆì»¤ ì¶”ê°€
                    top_locations = df_locations.nlargest(10, 'count')
                    for _, row in top_locations.iterrows():
                        folium.CircleMarker(
                            location=[row['lat'], row['lon']],
                            radius=row['count']/max(df_locations['count'])*10 + 5,
                            popup=f"{row['location']}: {row['count']}ê±´",
                            color='blue',
                            fill=True,
                            fill_opacity=0.4
                            ).add_to(m)
                        
                    return m
                    
                # íˆíŠ¸ë§µ ìƒì„± ë° í‘œì‹œ
                st.markdown("### ğŸ—ºï¸ ì§€ëª… ë¹ˆë„ìˆ˜ íˆíŠ¸ë§µ")
                heatmap = create_heatmap(location_counts, coords_dict)
                if heatmap:
                    folium_static(heatmap, width=800, height=600)
                    
                # ìƒìœ„ 20ê°œ ì§€ëª… í‘œì‹œ
                st.markdown("### ğŸ“Š ì§€ëª… ë¹ˆë„ìˆ˜ Top 20")
                df_top = pd.DataFrame({
                    'ì§€ëª…': list(location_counts.keys()),
                    'ë¹ˆë„ìˆ˜': list(location_counts.values())
                    }).sort_values('ë¹ˆë„ìˆ˜', ascending=False).head(20)
                    
                # ë¹ˆë„ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ ê·¸ë¼ë°ì´ì…˜ ì ìš©
                st.dataframe(
                    df_top.style.background_gradient(cmap='YlOrRd', subset=['ë¹ˆë„ìˆ˜']),
                    use_container_width=True
                    )
            else:
                st.warning("í‚¤ì›Œë“œì—ì„œ ì¸ì‹ëœ ì§€ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
            
        # ì—°ë„ë³„ ê¸°ì‚¬ ìˆ˜ ë¶„ì„
        st.markdown("---")
        st.header("ğŸ—ºï¸ ë¶„ì„ 2: ì—°ë„ë³„ ê¸°ì‚¬ ìˆ˜ ë¶„ì„")
        
        if 'ì—°ë„' in display_df.columns:
            year_counts = display_df["ì—°ë„"].value_counts().sort_index()
            
            fig1 = px.bar(
                x=year_counts.index,
                y=year_counts.values,
                labels={"x": "ì—°ë„", "y": "ê¸°ì‚¬ ìˆ˜"},
                title="ì—°ë„ë³„ ê¸°ì‚¬ ìˆ˜ ë¶„ì„"
            )
            st.plotly_chart(fig1, use_container_width=True)
        else:
            st.error("'ì—°ë„' ì»¬ëŸ¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()
        
        # í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ ë¶„ì„
        st.markdown("---")
        st.header("â˜ï¸ ë¶„ì„ 3: í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
        
        if 'í‚¤ì›Œë“œ' in display_df.columns:
            # í‚¤ì›Œë“œ ì²˜ë¦¬
            all_keywords = ",".join(display_df["í‚¤ì›Œë“œ"].dropna().astype(str)).split(",")
            filtered_keywords = [kw.strip() for kw in all_keywords if len(kw.strip()) > 1]
            keyword_freq = Counter(filtered_keywords)
            
            # ì›Œë“œí´ë¼ìš°ë“œì— í‘œì‹œí•  ìƒìœ„ í‚¤ì›Œë“œ ìˆ˜ ì¡°ì •
            st.subheader("ì›Œë“œí´ë¼ìš°ë“œ ì„¤ì •")
            top_n = st.slider("í‘œì‹œí•  ìƒìœ„ í‚¤ì›Œë“œ ìˆ˜", 10, 100, 20, 10)
            top_keywords = dict(keyword_freq.most_common(top_n))
            
            # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
            try:
                import json
                import random
                
                # ì›Œë“œí´ë¼ìš°ë“œ ë°ì´í„° ì¤€ë¹„
                words_js = []
                max_count = max(top_keywords.values()) if top_keywords else 1
                
                for word, count in top_keywords.items():
                    # í°íŠ¸ í¬ê¸° ê³„ì‚° (ë¹ˆë„ìˆ˜ì— ë¹„ë¡€)
                    size = 12 + int(40 * (count / max_count))
                    words_js.append({
                        'text': word,
                        'size': size,
                        'color': f'hsl({random.randint(0, 360)}, 70%, 50%)'
                    })
                
                # wordcloud ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
                from wordcloud import WordCloud
                import matplotlib.pyplot as plt
                
                # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
                wordcloud = WordCloud(
                    width=500,
                    height=200,
                    background_color='white',
                    font_path='CookieRun Regular.ttf',  # í”„ë¡œì íŠ¸ í´ë”ì˜ CookieRun í°íŠ¸ ì‚¬ìš©
                    max_words=top_n,
                    max_font_size=100,
                    random_state=42
                )
                
                # ì›Œë“œí´ë¼ìš°ë“œì— ë‹¨ì–´ ì¶”ê°€ ë° í‘œì‹œ
                wordcloud.generate_from_frequencies(top_keywords)
                plt.figure(figsize=(10, 6))
                plt.imshow(wordcloud, interpolation='bilinear')
                plt.axis('off')
                plt.tight_layout(pad=0)
                st.pyplot(plt.gcf())
                plt.close()
                
            except Exception as e:
                st.error(f'ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}')
                st.warning('í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ì°¨íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.')
                
                # í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ì°¨íŠ¸ í‘œì‹œ (í´ë°±)
                if top_keywords:
                    df = pd.DataFrame({
                        'í‚¤ì›Œë“œ': list(top_keywords.keys()),
                        'ë¹ˆë„ìˆ˜': list(top_keywords.values())
                    })
                    fig = px.bar(df, x='í‚¤ì›Œë“œ', y='ë¹ˆë„ìˆ˜', title='í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜')
                    st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("ì—…ë¡œë“œí•œ íŒŒì¼ì— 'í‚¤ì›Œë“œ' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")
            
        # ê¸°ê´€ ë„¤íŠ¸ì›Œí¬ ë¶„ì„
        st.markdown("---")
        st.header("ğŸ•¸ï¸ ë¶„ì„ 4: ê¸°ê´€ ë„¤íŠ¸ì›Œí¬ ë¶„ì„")
        
        if 'ê´€ë ¨ê¸°ê´€' in display_df.columns:
            # ê¸°ê´€ ë„¤íŠ¸ì›Œí¬ ë¶„ì„
            co_occurrence = Counter()
            for row in display_df["ê´€ë ¨ê¸°ê´€"].dropna():
                orgs = list(set([o.strip() for o in str(row).split(",") if len(o.strip()) > 1]))
                for i in range(len(orgs)):
                    for j in range(i+1, len(orgs)):
                        edge = tuple(sorted([orgs[i], orgs[j]]))
                        co_occurrence[edge] += 1
            
            # ë™ì‹œì¶œí˜„ 2íšŒ ì´ìƒë§Œ í•„í„°ë§
            filtered_edges = {pair: w for pair, w in co_occurrence.items() if w >= 2}
            
            G = nx.Graph()
            for (a, b), weight in filtered_edges.items():
                G.add_edge(a, b, weight=weight)
            
            if len(G.nodes()) > 0:
                # ìƒìœ„ ë…¸ë“œ ìˆ˜ ì¡°ì ˆ ìŠ¬ë¼ì´ë”
                max_nodes = min(30, len(G.nodes()))  # ìµœëŒ€ 50ê°œ ë…¸ë“œë¡œ ì œí•œ
                node_count = st.slider("ë¶„ì„í•  ìƒìœ„ ê¸°ê´€ ìˆ˜", 5, max_nodes, min(20, max_nodes), 1)
                
                # ì„ íƒí•œ ë…¸ë“œ ìˆ˜ë§Œí¼ ìƒìœ„ ë…¸ë“œ í•„í„°ë§
                top_nodes = sorted(G.degree, key=lambda x: x[1], reverse=True)[:node_count]
                G_filtered = G.subgraph([n for n, _ in top_nodes])
                
                st.write(f"ì„ íƒëœ ê¸°ê´€ ìˆ˜: {len(G_filtered.nodes())}")
                st.write(f"ì—°ê²° ìˆ˜: {len(G_filtered.edges())}")
                
                # ë…¸ë“œ ìœ„ì¹˜ ê³„ì‚°
                pos = nx.spring_layout(G_filtered, seed=42)
                
                # ì—£ì§€ ì¢Œí‘œ ì¶”ì¶œ
                edge_x, edge_y = [], []
                for edge in G_filtered.edges():
                    x0, y0 = pos[edge[0]]
                    x1, y1 = pos[edge[1]]
                    edge_x += [x0, x1, None]
                    edge_y += [y0, y1, None]
                
                # ì—£ì§€ íŠ¸ë ˆì´ìŠ¤
                edge_trace = go.Scatter(
                    x=edge_x, y=edge_y,
                    line=dict(width=0.5, color="#888"),
                    hoverinfo='none',
                    mode='lines'
                )
                
                # ë…¸ë“œ íŠ¸ë ˆì´ìŠ¤
                node_x, node_y, node_text = [], [], []
                for node in G_filtered.nodes():
                    x, y = pos[node]
                    node_x.append(x)
                    node_y.append(y)
                    node_text.append(f"{node}<br>ì—°ê²° ìˆ˜: {G_filtered.degree[node]}")
                
                # ë…¸ë“œì˜ ì—°ê²° ìˆ˜ì— ë”°ë¼ ìƒ‰ìƒ ê³„ì‚°
                node_degrees = [G_filtered.degree[node] for node in G_filtered.nodes()]
                
                node_trace = go.Scatter(
                    x=node_x, y=node_y,
                    mode='markers+text',
                    text=[node[:10] + '...' if len(node) > 10 else node for node in G_filtered.nodes()],
                    textposition="bottom center",
                    hovertext=node_text,
                    hoverinfo='text',
                    marker=dict(
                        size=10,
                        color=node_degrees,
                        colorscale='YlGnBu',
                        showscale=True,
                        colorbar=dict(
                            thickness=15,
                            title='ì—°ê²° ìˆ˜',
                            xanchor='left',
                            titleside='right'
                        ),
                        line=dict(width=2, color='DarkSlateGrey')
                    )
                )
                
                # ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±
                fig = go.Figure(
                    data=[edge_trace, node_trace],
                    layout=go.Layout(
                        showlegend=False,
                        hovermode='closest',
                        margin=dict(b=20,l=5,r=5,t=40),
                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
                    )
                )
                
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("ë„¤íŠ¸ì›Œí¬ë¥¼ ìƒì„±í•  ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("ì—…ë¡œë“œí•œ íŒŒì¼ì— 'ê´€ë ¨ê¸°ê´€' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
    <style>
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    .stDataFrame {
        width: 100%;
    }
    </style>
""", unsafe_allow_html=True)